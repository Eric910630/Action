# å°çº¢ä¹¦çˆ¬è™«ä¸‹ä¸€æ­¥å®æ–½æŒ‡å—

## å½“å‰çŠ¶æ€

âœ… **åŸºç¡€æ¡†æ¶å·²å®Œæˆ**:
- åˆ›å»ºäº† `XiaohongshuCrawler` ç±»
- é›†æˆåˆ° `HotspotMonitorService`
- æ·»åŠ äº†é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

âš ï¸ **å¾…å®Œå–„**:
- éœ€è¦åˆ†æå°çº¢ä¹¦å®é™…é¡µé¢ç»“æ„
- éœ€è¦å®ç°æ•°æ®è§£æé€»è¾‘
- å¯èƒ½éœ€è¦å¤„ç†åçˆ¬è™«æœºåˆ¶

## å®æ–½æ­¥éª¤

### æ­¥éª¤1ï¼šåˆ†æ BettaFish æºç ï¼ˆæœ€é‡è¦ï¼‰

**ç›®æ ‡**: å­¦ä¹  BettaFish å¦‚ä½•å®ç°å°çº¢ä¹¦æ•°æ®é‡‡é›†

**æ–¹æ³•**:
1. **è®¿é—® BettaFish GitHub ä»“åº“**:
   - https://github.com/666ghj/BettaFish
   - é‡ç‚¹å…³æ³¨ `MindSpider` ç›®å½•

2. **æŸ¥æ‰¾å°çº¢ä¹¦ç›¸å…³ä»£ç **:
   ```bash
   # åœ¨ BettaFish ä»“åº“ä¸­æœç´¢
   grep -r "xiaohongshu" MindSpider/
   grep -r "redbook" MindSpider/
   grep -r "å°çº¢ä¹¦" MindSpider/
   ```

3. **åˆ†æå…³é”®å®ç°**:
   - å¦‚ä½•æ„å»ºè¯·æ±‚
   - å¦‚ä½•å¤„ç†åçˆ¬è™«
   - å¦‚ä½•è§£ææ•°æ®
   - å¦‚ä½•ç®¡ç†Cookie/Session

4. **æå–å¯å¤ç”¨ä»£ç **:
   - å¤åˆ¶ç›¸å…³é€»è¾‘
   - é€‚é…åˆ°æˆ‘ä»¬çš„ `XiaohongshuCrawler`

### æ­¥éª¤2ï¼šåˆ†æå°çº¢ä¹¦å®é™…é¡µé¢

**ç›®æ ‡**: ç¡®å®šæ•°æ®æå–æ–¹æ³•

**æ–¹æ³•**:
1. **è®¿é—®å°çº¢ä¹¦çƒ­æœé¡µé¢**:
   - æ‰“å¼€æµè§ˆå™¨è®¿é—®å°çº¢ä¹¦
   - æ‰¾åˆ°çƒ­æœ/çƒ­é—¨å†…å®¹é¡µé¢
   - æ‰“å¼€å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰

2. **åˆ†æé¡µé¢ç»“æ„**:
   - æŸ¥çœ‹HTML DOMç»“æ„
   - æŸ¥æ‰¾çƒ­ç‚¹æ•°æ®çš„CSSé€‰æ‹©å™¨
   - æ£€æŸ¥æ˜¯å¦æœ‰APIè¯·æ±‚

3. **åˆ†æç½‘ç»œè¯·æ±‚**:
   - æŸ¥çœ‹Networkæ ‡ç­¾
   - æŸ¥æ‰¾è¿”å›çƒ­ç‚¹æ•°æ®çš„APIè¯·æ±‚
   - åˆ†æè¯·æ±‚å‚æ•°å’Œå“åº”æ ¼å¼

4. **è®°å½•å…³é”®ä¿¡æ¯**:
   - URLç»“æ„
   - è¯·æ±‚å¤´è¦æ±‚
   - å“åº”æ•°æ®æ ¼å¼
   - Cookieè¦æ±‚

### æ­¥éª¤3ï¼šå®ç°æ•°æ®è§£æ

**æ ¹æ®åˆ†æç»“æœï¼Œå®ç°è§£æé€»è¾‘**:

#### å¦‚æœæ˜¯HTMLé¡µé¢:

```python
def _parse_html(self, html: str) -> List[Dict[str, Any]]:
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(html, 'html.parser')
    
    # æ ¹æ®å®é™…DOMç»“æ„æå–
    hot_items = soup.select('.hot-item')  # éœ€è¦å®é™…éªŒè¯é€‰æ‹©å™¨
    
    hotspots = []
    for index, item in enumerate(hot_items, 1):
        title = item.select_one('.title').get_text(strip=True)
        url = item.select_one('a').get('href', '')
        
        hotspot = {
            "title": title,
            "url": self._normalize_url(url),
            "platform": "xiaohongshu",
            "rank": index,
            "heat_score": max(0, 100 - (index - 1)),
            "tags": [],
            "timestamp": datetime.now().isoformat(),
        }
        hotspots.append(hotspot)
    
    return hotspots
```

#### å¦‚æœæ˜¯JSON API:

```python
def _parse_json(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
    # æ ¹æ®å®é™…APIå“åº”æ ¼å¼
    items = data.get("data", {}).get("items", [])
    
    hotspots = []
    for index, item in enumerate(items, 1):
        hotspot = {
            "title": item.get("title", ""),
            "url": item.get("url", ""),
            "platform": "xiaohongshu",
            "rank": index,
            "heat_score": item.get("heat", max(0, 100 - (index - 1))),
            "tags": item.get("tags", []),
            "timestamp": datetime.now().isoformat(),
        }
        hotspots.append(hotspot)
    
    return hotspots
```

### æ­¥éª¤4ï¼šå¤„ç†åçˆ¬è™«

**æ ¹æ®å®é™…æƒ…å†µï¼Œæ·»åŠ åçˆ¬è™«å¤„ç†**:

1. **Cookieç®¡ç†**ï¼ˆå¦‚æœéœ€è¦ï¼‰:
   ```python
   # åœ¨ __init__ ä¸­åˆå§‹åŒ–Cookie
   self.cookies = {}
   
   # åœ¨è¯·æ±‚ä¸­ä½¿ç”¨Cookie
   async with httpx.AsyncClient(cookies=self.cookies) as client:
       response = await client.get(url, headers=headers)
   ```

2. **è¯·æ±‚é¢‘ç‡æ§åˆ¶**:
   ```python
   # åœ¨è¯·æ±‚ä¹‹é—´æ·»åŠ éšæœºå»¶è¿Ÿ
   await asyncio.sleep(random.uniform(1, 3))
   ```

3. **æµè§ˆå™¨è‡ªåŠ¨åŒ–**ï¼ˆå¦‚æœéœ€è¦ï¼‰:
   ```python
   # ä½¿ç”¨ Playwright æ¨¡æ‹Ÿæµè§ˆå™¨
   from playwright.async_api import async_playwright
   ```

### æ­¥éª¤5ï¼šæµ‹è¯•å’Œä¼˜åŒ–

1. **å•å…ƒæµ‹è¯•**:
   ```python
   # æµ‹è¯•æ•°æ®è§£æ
   crawler = XiaohongshuCrawler()
   html = "<html>...</html>"  # ç¤ºä¾‹HTML
   hotspots = crawler._parse_html(html)
   assert len(hotspots) > 0
   ```

2. **é›†æˆæµ‹è¯•**:
   ```bash
   # é€šè¿‡APIæµ‹è¯•
   curl -X POST http://localhost:8000/api/v1/hotspots/fetch?platform=xiaohongshu
   ```

3. **ç›‘æ§æ—¥å¿—**:
   ```bash
   # æŸ¥çœ‹æŠ“å–æ—¥å¿—
   tail -f logs/celery-worker.log | grep xiaohongshu
   ```

## ä¾èµ–å®‰è£…

å¦‚æœéœ€è¦HTMLè§£æï¼Œå®‰è£… beautifulsoup4:

```bash
cd backend
source venv/bin/activate
pip install beautifulsoup4 lxml
```

## å‚è€ƒèµ„æº

1. **BettaFish é¡¹ç›®**: 
   - GitHub: https://github.com/666ghj/BettaFish
   - é‡ç‚¹å…³æ³¨: `MindSpider` ç›®å½•

2. **BeautifulSoup æ–‡æ¡£**:
   - https://www.crummy.com/software/BeautifulSoup/bs4/doc/

3. **Playwright æ–‡æ¡£**ï¼ˆå¦‚æœéœ€è¦æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼‰:
   - https://playwright.dev/python/

## æ³¨æ„äº‹é¡¹

âš ï¸ **åˆè§„æ€§**:
- éµå®ˆå°çº¢ä¹¦ä½¿ç”¨æ¡æ¬¾
- éµå®ˆ robots.txt
- æ§åˆ¶è¯·æ±‚é¢‘ç‡
- ä»…ç”¨äºå­¦ä¹ ç ”ç©¶

âš ï¸ **æŠ€æœ¯æŒ‘æˆ˜**:
- åçˆ¬è™«æœºåˆ¶å¯èƒ½è¾ƒå¼º
- é¡µé¢ç»“æ„å¯èƒ½é¢‘ç¹å˜åŒ–
- å¯èƒ½éœ€è¦ç™»å½•æˆ–Cookie

## æ€»ç»“

âœ… **å·²å®Œæˆ**: åŸºç¡€æ¡†æ¶å’Œé›†æˆ

ğŸ“‹ **ä¸‹ä¸€æ­¥**: 
1. **æœ€é‡è¦**: åˆ†æ BettaFish çš„ MindSpider å®ç°
2. åˆ†æå°çº¢ä¹¦å®é™…é¡µé¢
3. å®ç°æ•°æ®è§£æé€»è¾‘
4. æµ‹è¯•å’Œä¼˜åŒ–

ç°åœ¨å¯ä»¥å¼€å§‹åˆ†æ BettaFish çš„æºç ï¼Œå­¦ä¹ å…¶å°çº¢ä¹¦æ•°æ®é‡‡é›†çš„å®ç°æ–¹å¼ï¼

